{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2814394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-05-13 19:41:02--  https://huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com/CHS/HCIP-AI%20EI%20Developer/V2.1/machine_translation/data.zip\n",
      "Resolving huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com (huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com)... 49.4.112.91, 49.4.112.3, 49.4.112.92\n",
      "Connecting to huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com (huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com)|49.4.112.91|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1071617 (1.0M) [application/zip]\n",
      "Saving to: 'data.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 1.31M 1s\n",
      "    50K .......... .......... .......... .......... ..........  9% 74.9M 0s\n",
      "   100K .......... .......... .......... .......... .......... 14% 2.67M 0s\n",
      "   150K .......... .......... .......... .......... .......... 19% 23.2M 0s\n",
      "   200K .......... .......... .......... .......... .......... 23% 94.9M 0s\n",
      "   250K .......... .......... .......... .......... .......... 28% 2.97M 0s\n",
      "   300K .......... .......... .......... .......... .......... 33%  141M 0s\n",
      "   350K .......... .......... .......... .......... .......... 38%  222M 0s\n",
      "   400K .......... .......... .......... .......... .......... 43%  113M 0s\n",
      "   450K .......... .......... .......... .......... .......... 47%  112M 0s\n",
      "   500K .......... .......... .......... .......... .......... 52% 89.6M 0s\n",
      "   550K .......... .......... .......... .......... .......... 57% 2.97M 0s\n",
      "   600K .......... .......... .......... .......... .......... 62%  114M 0s\n",
      "   650K .......... .......... .......... .......... .......... 66% 82.6M 0s\n",
      "   700K .......... .......... .......... .......... .......... 71% 98.0M 0s\n",
      "   750K .......... .......... .......... .......... .......... 76%  166M 0s\n",
      "   800K .......... .......... .......... .......... .......... 81%  127M 0s\n",
      "   850K .......... .......... .......... .......... .......... 86%  118M 0s\n",
      "   900K .......... .......... .......... .......... .......... 90%  123M 0s\n",
      "   950K .......... .......... .......... .......... .......... 95%  120M 0s\n",
      "  1000K .......... .......... .......... .......... ......    100% 97.0M=0.1s\n",
      "\n",
      "2022-05-13 19:41:03 (10.5 MB/s) - 'data.zip' saved [1071617/1071617]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://huawei-ai-certification.obs.cn-north-4.myhuaweicloud.com/CHS/HCIP-AI%20EI%20Developer/V2.1/machine_translation/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448f4bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "   creating: data/                 \n",
      "  inflating: data/cmn.txt            \n",
      "  inflating: data/cmn_zhsim.txt      \n"
     ]
    }
   ],
   "source": [
    "! unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb1fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.rc(\"font\", family='Microsoft YaHei')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecabf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data/cmn.txt\" \n",
    "## 数据集文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd834485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eng(w):\n",
    "    w = w.lower().strip()\n",
    "    # 单词和标点之间加空格\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "    # 多个空格合并为一个\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # 除了(a-z, A-Z, \".\", \"?\", \"!\", \",\")这些字符外，全替换成空格\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    # 增加开始结束标志，让模型知道何时停止预测\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "def preprocess_chinese(w):\n",
    "    w = w.lower().strip()\n",
    "    w = jieba.cut(w, cut_all=False, HMM=True)\n",
    "    w = \" \".join(list(w)) # 词之间增加空格\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb7b762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\28181\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.657 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> 我 可以 借 这 本书 吗 ？ <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = \"May I borrow this book?\"\n",
    "chn_sentence = \"我可以借这本书吗？\"\n",
    "print(preprocess_eng(en_sentence))\n",
    "print(preprocess_chinese(chn_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8218c2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start> hi . <end>', '<start> 嗨 。 <end>'],\n",
       " ['<start> hi . <end>', '<start> 你好 。 <end>'],\n",
       " ['<start> run . <end>', '<start> 你 用 跑 的 。 <end>'],\n",
       " ['<start> wait ! <end>', '<start> 等等 ！ <end>'],\n",
       " ['<start> hello ! <end>', '<start> 你好 。 <end>'],\n",
       " ['<start> i try . <end>', '<start> 让 我 来 。 <end>'],\n",
       " ['<start> i won ! <end>', '<start> 我 赢 了 。 <end>'],\n",
       " ['<start> oh no ! <end>', '<start> 不会 吧 。 <end>'],\n",
       " ['<start> cheers ! <end>', '<start> 乾杯 ! <end>'],\n",
       " ['<start> he ran . <end>', '<start> 他 跑 了 。 <end>'],\n",
       " ['<start> hop in . <end>', '<start> 跳进来 。 <end>'],\n",
       " ['<start> i lost . <end>', '<start> 我 迷失 了 。 <end>'],\n",
       " ['<start> i quit . <end>', '<start> 我 退出 。 <end>'],\n",
       " ['<start> i m ok . <end>', '<start> 我 沒事 。 <end>'],\n",
       " ['<start> listen . <end>', '<start> 听 着 。 <end>'],\n",
       " ['<start> no way ! <end>', '<start> 不 可能 ！ <end>'],\n",
       " ['<start> no way ! <end>', '<start> 没门 ！ <end>'],\n",
       " ['<start> really ? <end>', '<start> 你 确定 ？ <end>'],\n",
       " ['<start> try it . <end>', '<start> 试试 吧 。 <end>'],\n",
       " ['<start> we try . <end>', '<start> 我们 来 试试 。 <end>']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据，每个元素的样式是 [英文, 中文]\n",
    "def create_dataset(path, num_examples=None):\n",
    "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    word_pairs = [[preprocess_eng(w[0]), preprocess_chinese(w[1])]\n",
    "                   for w in word_pairs]\n",
    "    return word_pairs\n",
    "word_pairs = create_dataset(path_to_file)\n",
    "# 展示前 20 个数据\n",
    "word_pairs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c64c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言 ， 他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的 。 <end>\n",
      "20403 20403\n"
     ]
    }
   ],
   "source": [
    "en, chn = zip(*create_dataset(path_to_file))\n",
    "print(en[-1])\n",
    "print(chn[-1])\n",
    "# 显示数据大小\n",
    "print(len(en), len(chn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87de20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    # 取数据中的最大文本长度，用来将所有文本统一成一致的长度，模型才能够正常训练\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def tokenize(lang):\n",
    "    \"\"\"\n",
    "    1. 分词\n",
    "    2. 转换成 id\n",
    "    3. padding, 将每个句子统一成相同的长度，长度不足的后面补 0\n",
    "    \n",
    "    \"\"\"\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    filters='')\n",
    "    # 生成 词和 id 的映射词典 {word:id}\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    # 将词转换成对应的 id\n",
    "    text_ids = lang_tokenizer.texts_to_sequences(lang)\n",
    "    # 统一成相同的长度\n",
    "    padded_text_ids = tf.keras.preprocessing.sequence.pad_sequences(text_ids,\n",
    "    padding='post')\n",
    "    return padded_text_ids, lang_tokenizer\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # 加载数据，并做预处理\n",
    "    # 将中文设置为源语言，英文设置为目标语言\n",
    "    targ_lang, inp_lang = zip(*create_dataset(path, num_examples))\n",
    "    input_data, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_data, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    return input_data, target_data, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a192da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_examples 设置训练数据的大小\n",
    "# num_examples = 10000, 如果num examples = None 则表示不限制大小，所有样本用于训练\n",
    "num_examples = None\n",
    "input_data, target_data, inp_lang, targ_lang = load_dataset(\n",
    "    path_to_file, num_examples)\n",
    "# 计算中文数据和英文数据中的最大长度\n",
    "max_length_targ, max_length_inp = max_length(\n",
    "    target_data), max_length(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12983fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19382 19382 1021 1021\n"
     ]
    }
   ],
   "source": [
    "# 分割训练数据和验证数据\n",
    "input_train, input_val, target_train, target_val = train_test_split(\n",
    "    input_data, target_data, test_size=0.05)\n",
    "# 显示训练数据和验证数据的大小\n",
    "print(len(input_train), len(target_train),\n",
    "    len(input_val), len(target_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd3afb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：源语言：中文， 词和 id 的映射关系\n",
      "1 ----> <start>\n",
      "4 ----> 我\n",
      "137 ----> 必須\n",
      "585 ----> 立刻\n",
      "21 ----> 做\n",
      "17 ----> 嗎\n",
      "9 ----> ？\n",
      "2 ----> <end>\n",
      "\n",
      "输出：目标语言：英文， 词和 id 的映射关系\n",
      "1 ----> <start>\n",
      "25 ----> do\n",
      "4 ----> i\n",
      "21 ----> have\n",
      "6 ----> to\n",
      "25 ----> do\n",
      "15 ----> it\n",
      "145 ----> right\n",
      "204 ----> away\n",
      "9 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "## 查看 词和 id 的对应关系\n",
    "def convert(lang, data):\n",
    "    for t in data:\n",
    "        if t != 0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "print(\"输入：源语言：中文， 词和 id 的映射关系\")\n",
    "convert(inp_lang, input_train[0])\n",
    "print()\n",
    "print(\"输出：目标语言：英文， 词和 id 的映射关系\")\n",
    "convert(targ_lang, target_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "756781c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 32]), TensorShape([64, 38]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "# 0 是为 padding 保留的一个特殊 id， 所以要 + 1\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "# 先做 shuffle， 再取 batch\n",
    "# see https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_train, target_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01fd0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        # vacab_size=vocab_inp_size=9394, embedding_dim=256 enc_units=1024 batch_sz=64\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                        return_sequences=True,\n",
    "                                        return_state=True,\n",
    "                                        #recurrent_activation='sigmoid',\n",
    "                                        recurrent_initializer='glorot_uniform')\n",
    "    def call(self, x, hidden):\n",
    "        # x 是训练数据，shape == (batch_size，max_length) -> (64, 46)\n",
    "        # embedding 后得到每个词的词向量, x shape == (batch_size, max_length, embedding_dim) -> (64, 46, 256)\n",
    "        x = self.embedding(x)\n",
    "        # 在 GRU 中，每一个时间步，输出层和隐藏层是相等的\n",
    "        # output 是所有时间步的输出层输出 shape == (batch_size, max_length, units) -> (64, 46, 1024)\n",
    "        # state 是最后一个时间步的隐藏层输出, shape == (batch_size, units) -> (64, 1024)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    def initialize_hidden_state(self):\n",
    "        # 初始化 gru 的隐层参数, shape == (batch_size, units) -> (64,1024)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "155c5d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder 输出的维度: (batch size, sequence length, units) (64, 32, 512)\n",
      "Encoder 隐层的维度: (batch size, units) (64, 512)\n",
      "tf.Tensor(\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True], shape=(512,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "# encoder 示例输出\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder 输出的维度: (batch size, sequence length, units) {}'.format(\n",
    "    sample_output.shape))\n",
    "print('Encoder 隐层的维度: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "# GRU,在每一个时间步，隐层和输出层是相等的\n",
    "print(sample_output[-1, -1, :] == sample_hidden[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1280cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # 扩展时间维度 shape == (batch_size, 1, hidden size)\n",
    "        # 为了计算后面的 score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # score 维度为 1 是因为应用了 self.V, V 的维度是 1\n",
    "        # 应用 self.V 前后的维度是 (batch_size, max_length, units) --> (batch_size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        # 使用 softmax 得到 attention 的权重， attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        # 相加后的 attention 上下文向量的维度：shape context_vector == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7211414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention 输出的维度: (batch size, units) (64, 512)\n",
      "Attention 权值参数的维度: (batch_size, sequence_length, 1) (64, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(\n",
    "    sample_hidden, sample_output)\n",
    "print(\"Attention 输出的维度: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention 权值参数的维度: (batch_size, sequence_length, 1) {}\".format(\n",
    "attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca12f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        # vocab_size=vocab_tar_size=6082, embedding_dim=256, dec_units=1024, batch_sz=64\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "        return_sequences=True,\n",
    "        return_state=True,\n",
    "        recurrent_initializer='glorot_uniform')\n",
    "        # 输出的维度是目标语言词汇表的大小，返回的是 softmax 概率，词汇表中每一个词的概率\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        # attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # This function outputs a result at each timestamp\n",
    "        # 计算 decoder 的第一个隐状态和 encoder 所有输入之间的 attention 权重， 得到上下文向量,context_vector\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # embedding 后的维度 == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        # 把上下文向量 context_vector 和 输入 embedding 拼接在一起\n",
    "        # context_vector shape == (batch_size, units) -> (64, 1024)\n",
    "        # 拼接后的数据维度 == (batch_size, 1, embedding_dim + hidden_size) -> (64, 1, 1024 + 256)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # 把拼接后的向量输入 gru\n",
    "        # 得到当前时间步的输出和隐状态\n",
    "        # output shape == (batch_size, 1, units) -> (64, 1, 1024), state shape == (batch_size, units) -> (64,1024)\n",
    "        output, state = self.gru(x)\n",
    "        # output shape == (batch_size, hidden_size=1024)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # output shape == (batch_size, vocab) -> (64, 6082)\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae13a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder 输出的维度: (batch_size, vocab size) (64, 6095)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                         sample_hidden, sample_output)\n",
    "print('Decoder 输出的维度: (batch_size, vocab size) {}'.format(\n",
    "sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af3c602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate the loss value\n",
    "    Args:\n",
    "    real: the true label shape == (batch_size,) -> (64,)\n",
    "    pred: the probability of each word from the vocabulary, is the output from the decoder \n",
    "    shape == (batch_size, vocab_size) -> (64, 6082)\n",
    "    Returns: \n",
    "    the average loss of the data in a batch size\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c26ff24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/chinese-eng'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34fd82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        # feed the <start> as the first input of the decoder\n",
    "        # dec input shape == (batch_size, 1) -> (64, 1)\n",
    "        dec_input = tf.expand_dims(\n",
    "        [targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        # because of the data preprocessing(add a start token to the sentence)\n",
    "        # the first word is <start>, so t starts from 1(not 0)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(\n",
    "                dec_input, dec_hidden, enc_output)\n",
    "            # targ[:, t] is the true label(index of the word) of every sentence(in a batch) at the current timestamp\n",
    "            # like [ 85 18 25 25 ··· 1047 79 13], shape == (batch_size,) -> (64,)\n",
    "            # predictions shape == (batch_size, vocab_size) -> (64, 6082)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "     # collect all trainable variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    # calculate the gradients for the whole variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    # apply the gradients on the variables\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6d3cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.9493\n",
      "Epoch 1 Batch 100 Loss 1.1924\n",
      "Epoch 1 Batch 200 Loss 1.0832\n",
      "Epoch 1 Batch 300 Loss 1.0737\n",
      "Epoch 1 Loss 1.1340\n",
      "Epoch 2 Batch 0 Loss 1.0221\n",
      "Epoch 2 Batch 100 Loss 1.0037\n",
      "Epoch 2 Batch 200 Loss 0.8758\n",
      "Epoch 2 Batch 300 Loss 0.8927\n",
      "Epoch 2 Loss 0.9272\n",
      "Time taken for 1 epoch 63.1968195438385 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2 # 50 测试需要，设置训练轮数为 2， 实际为保证效果，建议设置为 50\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    # 获取 gru 的初始状态\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch,batch_loss.numpy()))\n",
    "    # 每两个迭代保存一次模型\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60e06e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \"\"\"Translate a sentence\n",
    "    Args:\n",
    "        sentence: the test sentence \n",
    "    \"\"\"\n",
    "    # max_length_targ 38, max_length_inp 64\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_chinese(sentence)\n",
    "    # convert each word to the index in the test sentence\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    # hidden shape == (1, 1024)\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
    "    # enc hidden shape == (1, 1024)\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,dec_hidden,enc_out)\n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        # print(attention_weights)\n",
    "        # get the index which has the highest probability\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        # convert the index to the word\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        # when the decoder predicts the end, stop prediction\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        # the predicted id is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    # maybe you need to change the fname based on your system, so that the Chinese can be displayed in the plot\n",
    "    # font = FontProperties(fname=r\"C:\\\\WINDOWS\\\\Fonts\\\\simsun.ttc\", size=14)\n",
    "    # set the size of the plot\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # cmap means color map, viridis means blue-green-yellow\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    # set the x-tick/y-tick labels with list of string labels\n",
    "    # ax.set_xticklabels([''] + sentence, fontdict=fontdict, fontproperties=font)\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict)\n",
    "    # ax.set_yticklabels([''] + predicted_sentence, fontproperties=font, fontdict=fontdict)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    # set tick locators\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(\n",
    "        result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ad62aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/chinese-eng\\ckpt-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2020c8772c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = 'checkpoints/chinese-eng'\n",
    "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f45f2d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 我 有 一只 猫 <end>\n",
      "Predicted translation: i m a good . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('我有一只猫')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333af19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc60c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
